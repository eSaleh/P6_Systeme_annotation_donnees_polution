{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fonction qui permet de prendre des photos avec un délais en secondes cf doc : https://docs.python.org/3/library/time.html#time.sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import picamera\n",
    "\n",
    "def capture_image(output_file):\n",
    "    with picamera.PiCamera() as camera:\n",
    "        # Optional: Set camera resolution\n",
    "        # camera.resolution = (1280, 720)\n",
    "        \n",
    "        # Optional: Set camera rotation (0, 90, 180, or 270 degrees)\n",
    "        # camera.rotation = 90\n",
    "        \n",
    "        # Capture an image\n",
    "        camera.start_preview()\n",
    "        # Add a delay if needed to let the camera adjust to lighting conditions\n",
    "        time.sleep(2)\n",
    "        camera.capture(output_file)\n",
    "        camera.stop_preview()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_file = \"image.jpg\"  # Change this to the desired output filename\n",
    "    capture_image(output_file)\n",
    "    print(f\"Image captured and saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La même chose mais pour une vidéo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import picamera\n",
    "from time import sleep\n",
    "\n",
    "def capture_video(output_file, duration):\n",
    "    with picamera.PiCamera() as camera:\n",
    "        # Optional: Set camera resolution\n",
    "        # camera.resolution = (1280, 720)\n",
    "        \n",
    "        # Optional: Set camera rotation (0, 90, 180, or 270 degrees)\n",
    "        # camera.rotation = 90\n",
    "        \n",
    "        camera.start_recording(output_file)\n",
    "        sleep(duration)\n",
    "        camera.stop_recording()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_file = \"video.h264\"  # Change this to the desired output filename\n",
    "    duration = 10  # Change this to the desired duration of the video in seconds\n",
    "    capture_video(output_file, duration)\n",
    "    print(f\"Video captured and saved as {output_file}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Un premier système d'annotation utilisant yolov3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import picamera\n",
    "import picamera.array\n",
    "\n",
    "def track_objects(camera_resolution=(640, 480)):\n",
    "    # Charger le modèle de détection d'objets (exemple : YOLOv3)\n",
    "    net = cv2.dnn.readNet(\"yolov3.weights\", \"yolov3.cfg\")\n",
    "    classes = []\n",
    "    with open(\"coco.names\", \"r\") as f:\n",
    "        classes = [line.strip() for line in f.readlines()]\n",
    "    layer_names = net.getLayerNames()\n",
    "    output_layers = [layer_names[i[0] - 1] for i in net.getUnconnectedOutLayers()]\n",
    "\n",
    "    # Initialiser le suivi de Centroid\n",
    "    trackers = cv2.MultiTracker_create()\n",
    "\n",
    "    with picamera.PiCamera() as camera:\n",
    "        camera.resolution = camera_resolution\n",
    "        with picamera.array.PiRGBArray(camera) as stream:\n",
    "            for frame in camera.capture_continuous(stream, format='bgr', use_video_port=True):\n",
    "                img = frame.array\n",
    "\n",
    "                if len(trackers.getObjects()) == 0:\n",
    "                    # Pas de suivi en cours, détecter les objets\n",
    "                    blob = cv2.dnn.blobFromImage(img, 0.00392, (416, 416), (0, 0, 0), True, crop=False)\n",
    "                    net.setInput(blob)\n",
    "                    outs = net.forward(output_layers)\n",
    "\n",
    "                    # Traiter les détections\n",
    "                    boxes = []\n",
    "                    for out in outs:\n",
    "                        for detection in out:\n",
    "                            scores = detection[5:]\n",
    "                            class_id = np.argmax(scores)\n",
    "                            confidence = scores[class_id]\n",
    "                            if confidence > 0.5:\n",
    "                                # Récupérer les coordonnées de la boîte englobante\n",
    "                                center_x = int(detection[0] * camera_resolution[0])\n",
    "                                center_y = int(detection[1] * camera_resolution[1])\n",
    "                                w = int(detection[2] * camera_resolution[0])\n",
    "                                h = int(detection[3] * camera_resolution[1])\n",
    "\n",
    "                                boxes.append((center_x - w // 2, center_y - h // 2, w, h))\n",
    "\n",
    "                    # Initialiser les trackers pour les boîtes englobantes détectées\n",
    "                    for box in boxes:\n",
    "                        tracker = cv2.TrackerCSRT_create()\n",
    "                        trackers.add(tracker, img, (box[0], box[1], box[2], box[3]))\n",
    "\n",
    "                # Actualiser le suivi pour chaque objet\n",
    "                (success, boxes) = trackers.update(img)\n",
    "                for box in boxes:\n",
    "                    (x, y, w, h) = [int(v) for v in box]\n",
    "                    cv2.rectangle(img, (x, y), (x + w, y + h), (0, 255, 0), 2)\n",
    "\n",
    "                # Afficher le flux vidéo avec les boîtes englobantes\n",
    "                cv2.imshow('Camera', img)\n",
    "                if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "\n",
    "                stream.truncate(0)\n",
    "\n",
    "    cv2.destroyAllWindows()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    track_objects()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dans cet exemple :\n",
    "\n",
    "    Nous avons utilisé le suivi de Centroid pour suivre les objets détectés dans le flux vidéo.\n",
    "    Lorsqu'aucun objet n'est suivi, nous détectons les objets à l'aide de YOLOv3 et initialisons les trackers pour ces objets.\n",
    "    Les trackers sont ensuite mis à jour à chaque image du flux vidéo pour suivre les objets détectés.\n",
    "\n",
    "Assurez-vous d'avoir téléchargé les fichiers du modèle YOLOv3 (yolov3.weights, yolov3.cfg, coco.names) et d'avoir les bibliothèques OpenCV et picamera installées sur votre Raspberry Pi. Vous devrez peut-être ajuster les chemins des fichiers du modèle et les paramètres de résolution de la caméra en fonction de vos besoins."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
